{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMOD 5410 Big Data - Weekly Assignment \\# 1\n",
    "## Detecting Russian Twitter Bots\n",
    "\n",
    "### By: Matt Emmons and Edgar Khackatryan\n",
    "\n",
    "* Find a data source, write/use a tool that gathers up some data (e.g. scrapes twitter or uses a google API)\n",
    "* Prepare somewhere between ½ and 1 page of a description of what your data is, and a simple hypotheses on why this might have something interesting we can do with it\n",
    "\n",
    "The goal of this dataset is to explore the tweets of certain known Russian twitter 'trolls' and bots to explore the keywords, frequency of tweets and certain tendencies. These accounts often feign as being pro-right American individuals but often have highly coordinated agendas, the goal being to spread information or disinformation amongst other users on social media. The platform we are focused on will be twitter for its ease of use in scraping the relevant tweets from known deviant users. Interestingly, Twitter itself released a new set of statistics regarding their own internal investigation into Russian efforts to influence the 2016 Presidential election revealing that more than 50,000 automated accounts have links to Russian government ministries and Russia-linked organizations, specifically the IRA (Internet Research Agency).\n",
    "\n",
    "The data being used will mainly be individual from users who commonly participate in online discourse surrounding American politics, with focus on talking points and hashtags that are related to current affairs. Twitter's API provides user-controlled geolocation information and date-times of all tweets involved, included lists of users who liked, retweets and responded to questionable posts. This dataset can continually be expanded as long as Twitter's ratelimiting is not exceeded, but for now the dataset will remain small for prototyping techniques at identifying trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import config as cfg\n",
    "import pandas as pd\n",
    "from pprint import pprint as pprint\n",
    "from twython import Twython, TwythonError\n",
    "from IPython.display import display\n",
    "\n",
    "# authenticate with Twitter API\n",
    "twitter = Twython(cfg.APP_KEY, cfg.APP_SECRET, oauth_version=2)\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "twitter = Twython(cfg.APP_KEY, access_token = ACCESS_TOKEN)\n",
    "\n",
    "# tweets storage file\n",
    "JSON_FILE = \"data/tweets.json\"    \n",
    "CSV_FILE = \"data/tweets.csv\"\n",
    "\n",
    "def get_rate_limit():\n",
    "    '''Function that returns current Twitter API rate limit'''\n",
    "    return twitter.get_application_rate_limit_status()['resources']['search']\n",
    "\n",
    "def load_tweets(file):\n",
    "    '''Function that loads tweets from JSON file'''\n",
    "    with open(file, 'r') as f:\n",
    "        tweets = json.load(f)\n",
    "        return tweets\n",
    "\n",
    "def write_tweets(tweets, filename):\n",
    "    ''' Function that appends tweets to a file. '''\n",
    "    with open(filename, 'a') as f:\n",
    "        json.dump(tweets, f)\n",
    "            \n",
    "def write_csv(data_frame, filename):\n",
    "    ''' Function to write dataframe to CSV file'''\n",
    "    data_frame.to_csv(filename, sep = ',', encoding = 'utf-8')\n",
    "    \n",
    "def read_csv(filename):\n",
    "    '''Function that returns a dataframe read from filename'''\n",
    "    return pd.read_csv(filename, header = 0, index_col = 0)\n",
    "    \n",
    "def get_tweets(user, num = 25):\n",
    "    '''\n",
    "    Function that retrives _num_ tweets from user by username\n",
    "    Returns an array of tweets\n",
    "    '''\n",
    "    tweet_array = []\n",
    "    try:\n",
    "        user_timeline = twitter.get_user_timeline(\n",
    "            screen_name = user,\n",
    "            count = num\n",
    "        )\n",
    "        for tweets in user_timeline:\n",
    "            tweet_array.append(tweets)\n",
    "    except TwythonError as e:\n",
    "        print(\"Error with {}, {}\".format(user, e))\n",
    "    return tweet_array\n",
    "    \n",
    "def delete_tweets_file(filename):\n",
    "    '''\n",
    "    Function to remove tweets file\n",
    "    USE WITH CAUTION!\n",
    "    '''\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 450, 'remaining': 450, 'reset': 1516729203}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEMP: delete the tweets.json file\n",
    "# delete_tweets_file(JSON_FILE)\n",
    "get_rate_limit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: functionize this stuff\n",
    "# known russian twitter agents\n",
    "users = [\n",
    "    'smartdissent',\n",
    "    'SparkleSoup45',\n",
    "    'bbusa617',\n",
    "    'charlieJuliet',\n",
    "    'ChrisFromWI',\n",
    "    'SCroixFreePress',\n",
    "    'wienerherzog2',\n",
    "    'PeggyRuppe',\n",
    "    'remleona',\n",
    "    'Answers2b4u',\n",
    "]\n",
    "\n",
    "fields  = {\n",
    "    'tweet_id':     [],\n",
    "    'user_id':      [],\n",
    "    'screen_name':  [],\n",
    "    'created_at':   [],\n",
    "    'text':         [],\n",
    "}\n",
    "\n",
    "# prevents casting user_id and tweet_id fields to float\n",
    "df = pd.DataFrame(fields, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tweets_to_df(tweet_array, fields_dict, data_frame):\n",
    "    '''\n",
    "    Function to add tweets to existing dataframe\n",
    "    Drops duplicate values\n",
    "    '''\n",
    "    for tweet in tweet_array:\n",
    "        fields_dict['tweet_id'].append(tweet['id'])\n",
    "        fields_dict['user_id'].append(tweet['user']['id'])\n",
    "        fields_dict['screen_name'].append(tweet['user']['screen_name'])\n",
    "        fields_dict['created_at'].append(tweet['created_at'])\n",
    "        fields_dict['text'].append(tweet['text'])\n",
    "    temp_df = pd.DataFrame(fields_dict)\n",
    "    data_frame = pd.concat([temp_df, data_frame])#, ignore_index = True)\n",
    "#     data_frame.drop_duplicates()\n",
    "#     data_frame.reset_index(drop = True)\n",
    "    data_frame['created_at'] = pd.to_datetime(data_frame['created_at'])\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "for user in users:\n",
    "    tweets = get_tweets(user, num = 20)\n",
    "    df = add_tweets_to_df(tweets, fields, df)  \n",
    "\n",
    "write_csv(df, CSV_FILE)\n",
    "\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# display(df.dtypes)\n",
    "# display(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2018-01-23 17:19:22</td>\n",
       "      <td>smartdissent</td>\n",
       "      <td>RT @nytpolitics: You probably don’t realize just how much influence Nafta has on your daily life — even the products we think of as quintes…</td>\n",
       "      <td>955852472173711361</td>\n",
       "      <td>826982179204915200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2018-01-23 17:18:50</td>\n",
       "      <td>smartdissent</td>\n",
       "      <td>RT @NAACP: One of the many daughters of the civil rights movement! Ms. Fannie Lou Hamer. https://t.co/k8qDS1z0Dk</td>\n",
       "      <td>955852334793416704</td>\n",
       "      <td>826982179204915200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2018-01-23 17:18:42</td>\n",
       "      <td>smartdissent</td>\n",
       "      <td>RT @kylegriffin1: The Trump administration is reportedly waiving dozens of environmental regulations to speed up construction of the border…</td>\n",
       "      <td>955852304414109696</td>\n",
       "      <td>826982179204915200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2018-01-23 17:10:12</td>\n",
       "      <td>smartdissent</td>\n",
       "      <td>NEW: @realDonaldTrump Restarted the #Sabotage of #ObamaCare in early January https://t.co/S3sVvbzLKd #SmartDissent… https://t.co/gzH6KIvNoG</td>\n",
       "      <td>955850162819293184</td>\n",
       "      <td>826982179204915200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>2018-01-23 17:05:12</td>\n",
       "      <td>smartdissent</td>\n",
       "      <td>NEW: Hidden between #Christmas &amp;amp; #NewYearsEve, @realDonaldTrump's Admin Granted Anti-Environment Favors to… https://t.co/oKZu043Goj</td>\n",
       "      <td>955848906998472705</td>\n",
       "      <td>826982179204915200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              created_at   screen_name  \\\n",
       "0.0  2018-01-23 17:19:22  smartdissent   \n",
       "1.0  2018-01-23 17:18:50  smartdissent   \n",
       "2.0  2018-01-23 17:18:42  smartdissent   \n",
       "3.0  2018-01-23 17:10:12  smartdissent   \n",
       "4.0  2018-01-23 17:05:12  smartdissent   \n",
       "\n",
       "                                                                                                                                             text  \\\n",
       "0.0  RT @nytpolitics: You probably don’t realize just how much influence Nafta has on your daily life — even the products we think of as quintes…   \n",
       "1.0  RT @NAACP: One of the many daughters of the civil rights movement! Ms. Fannie Lou Hamer. https://t.co/k8qDS1z0Dk                               \n",
       "2.0  RT @kylegriffin1: The Trump administration is reportedly waiving dozens of environmental regulations to speed up construction of the border…   \n",
       "3.0  NEW: @realDonaldTrump Restarted the #Sabotage of #ObamaCare in early January https://t.co/S3sVvbzLKd #SmartDissent… https://t.co/gzH6KIvNoG    \n",
       "4.0  NEW: Hidden between #Christmas &amp; #NewYearsEve, @realDonaldTrump's Admin Granted Anti-Environment Favors to… https://t.co/oKZu043Goj        \n",
       "\n",
       "               tweet_id             user_id  \n",
       "0.0  955852472173711361  826982179204915200  \n",
       "1.0  955852334793416704  826982179204915200  \n",
       "2.0  955852304414109696  826982179204915200  \n",
       "3.0  955850162819293184  826982179204915200  \n",
       "4.0  955848906998472705  826982179204915200  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "created_at     2018-01-23 17:18:50                                                                                             \n",
       "screen_name    smartdissent                                                                                                    \n",
       "text           RT @NAACP: One of the many daughters of the civil rights movement! Ms. Fannie Lou Hamer. https://t.co/k8qDS1z0Dk\n",
       "tweet_id       955852334793416704                                                                                              \n",
       "user_id        826982179204915200                                                                                              \n",
       "Name: 1.0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load existing CSV and perform analysis\n",
    "df = read_csv(CSV_FILE)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
