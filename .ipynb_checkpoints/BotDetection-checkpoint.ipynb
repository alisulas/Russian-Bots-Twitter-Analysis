{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(101)\n",
    "rand_seed = 101\n",
    "\n",
    "n_rows = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.4 s, sys: 11.7 s, total: 45.1 s\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ROOT = \"./csv\"\n",
    "df = pd.read_csv(\n",
    "    ROOT + \"/mergedtweets.csv\", \n",
    "    encoding='utf-8', \n",
    "    low_memory=False, \n",
    "    parse_dates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2203451, 19)\n",
      "      user_id         user_key     created_at          created_str  \\\n",
      "0  2532611755        kathiemrr  1488207240000  2017-02-27 14:54:00   \n",
      "1  2531159968   traceyhappymom  1471272620000  2016-08-15 14:50:20   \n",
      "2           0    evewebster373  1435701369000  2015-06-30 21:56:09   \n",
      "3  4840551713      blacktolive  1474013088000  2016-09-16 08:04:48   \n",
      "4  1694026190  jacquelinisbest  1474227985000  2016-09-18 19:46:25   \n",
      "\n",
      "   retweet_count  retweeted  favorite_count  \\\n",
      "0              0       True               0   \n",
      "1              0       True               0   \n",
      "2              0       True               0   \n",
      "3             18      False              17   \n",
      "4              0      False               0   \n",
      "\n",
      "                                                text            tweet_id  \\\n",
      "0    #ThingsDoneByMistake kissing auntie in the lips  836227891897651200   \n",
      "1  RT @mc_derpin: #TheOlderWeGet the more pessimi...  765198948239810560   \n",
      "2  RT @dmataconis: Ready To Feel Like A Failure? ...  616002306572746752   \n",
      "3    Amen! #blacklivesmatter https://t.co/wGffaOqgzl  776693302926147584   \n",
      "4  RT @NahBabyNah: Twitchy: Chuck Todd caught out...  777594647875059712   \n",
      "\n",
      "                                              source                 hashtags  \\\n",
      "0                                                NaN  [\"ThingsDoneByMistake\"]   \n",
      "1                                                NaN        [\"TheOlderWeGet\"]   \n",
      "2                                                NaN                       []   \n",
      "3  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...     [\"Blacklivesmatter\"]   \n",
      "4  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...        [\"WakeUpAmerica\"]   \n",
      "\n",
      "                                 expanded_urls        mentions  \\\n",
      "0                                           []              []   \n",
      "1                                           []              []   \n",
      "2                                           []              []   \n",
      "3                                           []              []   \n",
      "4  [\"http://ln.is/twitchy.com/loriz-31/3yafU\"]  [\"nahbabynah\"]   \n",
      "\n",
      "   retweeted_status_id  in_reply_to_status_id  class  \\\n",
      "0                    0                      0    1.0   \n",
      "1                    0                      0    1.0   \n",
      "2                    0                      0    1.0   \n",
      "3                    0                      0    1.0   \n",
      "4   777591478206029824                      0    1.0   \n",
      "\n",
      "                                      tokenized_text  \\\n",
      "0  ['#ThingsDoneByMistake', 'kissing', 'auntie', ...   \n",
      "1  ['RT', '@mc_derpin', ':', '#TheOlderWeGet', 't...   \n",
      "2  ['RT', '@dmataconis', ':', 'Ready', 'To', 'Fee...   \n",
      "3  ['Amen', '!', '#blacklivesmatter', 'https://t....   \n",
      "4  ['RT', '@NahBabyNah', ':', 'Twitchy', ':', 'Ch...   \n",
      "\n",
      "                                           stem_text  \\\n",
      "0     ['thingsdonebymistak', 'kiss', 'aunty', 'lip']   \n",
      "1  ['rt', 'mc_derpin', '', 'theolderweget', 'pess...   \n",
      "2  ['rt', 'dmatacon', '', 'ready', 'feel', 'lik',...   \n",
      "3                    ['am', '', 'blacklivesmat', '']   \n",
      "4  ['rt', 'nahbabynah', '', 'twitchy', '', 'chuck...   \n",
      "\n",
      "                                          lemma_text  \n",
      "0  ['thingsdonebymistake', 'kiss', 'auntie', 'lips']  \n",
      "1  ['rt', 'mc_derpin', '', 'theolderweget', 'pess...  \n",
      "2  ['rt', 'dmataconis', '', 'ready', 'feel', 'lik...  \n",
      "3               ['amen', '', 'blacklivesmatter', '']  \n",
      "4  ['rt', 'nahbabynah', '', 'twitchy', '', 'chuck...  \n",
      "                    user_id         user_key     created_at  \\\n",
      "2203446  963619824265023488        aviviavai  1518579843952   \n",
      "2203447  963619824503894016  davidinkuwait69  1518579844009   \n",
      "2203448  963619824768376833     trumpliesbot  1518579844072   \n",
      "2203449  963619825229611008        SteveoUSA  1518579844182   \n",
      "2203450  963619825036783618       RichieRoby  1518579844136   \n",
      "\n",
      "                            created_str  retweet_count  retweeted  \\\n",
      "2203446  Wed Feb 14 03:44:03 +0000 2018              0      False   \n",
      "2203447  Wed Feb 14 03:44:04 +0000 2018              0      False   \n",
      "2203448  Wed Feb 14 03:44:04 +0000 2018              0      False   \n",
      "2203449  Wed Feb 14 03:44:04 +0000 2018              0      False   \n",
      "2203450  Wed Feb 14 03:44:04 +0000 2018              0      False   \n",
      "\n",
      "         favorite_count                                               text  \\\n",
      "2203446               0  b'RT @NicCageMatch: White People Once Kept Bla...   \n",
      "2203447               0  b'The Ex Resident Obama used Kehinde Wiley to ...   \n",
      "2203448               0  b\"Come on #MAGA, admit it. Trump and his co-co...   \n",
      "2203449               0  b'History will show that @GenFlynn was a patri...   \n",
      "2203450               0  b'Not sure how one does better than applying t...   \n",
      "\n",
      "                   tweet_id  \\\n",
      "2203446  963619824265023488   \n",
      "2203447  963619824503894016   \n",
      "2203448  963619824768376833   \n",
      "2203449  963619825229611008   \n",
      "2203450  963619825036783618   \n",
      "\n",
      "                                                    source  hashtags  \\\n",
      "2203446  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...        []   \n",
      "2203447  <a href=\"http://twitter.com/download/android\" ...        []   \n",
      "2203448  <a href=\"http://twitter.com/trumpliesbot\" rel=...  ['MAGA']   \n",
      "2203449  <a href=\"http://www.twitter.com\" rel=\"nofollow...        []   \n",
      "2203450  <a href=\"https://about.twitter.com/products/tw...        []   \n",
      "\n",
      "                                             expanded_urls  \\\n",
      "2203446  ['https://twitter.com/thewrap/status/963161707...   \n",
      "2203447                                                 []   \n",
      "2203448                                                 []   \n",
      "2203449                                                 []   \n",
      "2203450  ['https://twitter.com/i/web/status/96361982503...   \n",
      "\n",
      "                             mentions  retweeted_status_id  \\\n",
      "2203446              ['NicCageMatch']   963170112567201792   \n",
      "2203447              ['ElderLansing']   963249595949158400   \n",
      "2203448               ['OMGno2trump']   963607817839153152   \n",
      "2203449  ['johncardillo', 'GenFlynn']   963394200069951488   \n",
      "2203450                            []                    0   \n",
      "\n",
      "         in_reply_to_status_id  class  \\\n",
      "2203446                      0    NaN   \n",
      "2203447                      0    NaN   \n",
      "2203448                      0    NaN   \n",
      "2203449                      0    NaN   \n",
      "2203450                      0    NaN   \n",
      "\n",
      "                                            tokenized_text  \\\n",
      "2203446  [\"b'RT\", '@NicCageMatch', ':', 'White', 'Peopl...   \n",
      "2203447  [\"b'The\", 'Ex', 'Resident', 'Obama', 'used', '...   \n",
      "2203448  ['b', '\"', 'Come', 'on', '#MAGA', ',', 'admit'...   \n",
      "2203449  [\"b'History\", 'will', 'show', 'that', '@GenFly...   \n",
      "2203450  [\"b'Not\", 'sure', 'how', 'one', 'does', 'bette...   \n",
      "\n",
      "                                                 stem_text  \\\n",
      "2203446  ['rt', 'niccagematch', '', 'whit', 'peopl', 'k...   \n",
      "2203447  ['e', 'resid', 'obam', 'us', 'kehind', 'wiley'...   \n",
      "2203448  ['', 'com', 'mag', '', 'admit', '', 'trump', '...   \n",
      "2203449  ['hist', 'show', 'genflyn', 'patriot', 'malicy...   \n",
      "2203450  ['sur', 'on', 'bet', 'apply', 'rul', 'law', 'i...   \n",
      "\n",
      "                                                lemma_text  \n",
      "2203446  ['rt', 'niccagematch', '', 'white', 'people', ...  \n",
      "2203447  ['e', 'resident', 'obama', 'use', 'kehinde', '...  \n",
      "2203448  ['', 'come', 'maga', '', 'admit', '', 'trump',...  \n",
      "2203449  ['history', 'show', 'genflynn', 'patriot', 'ma...  \n",
      "2203450  ['sure', 'one', 'better', 'apply', 'rule', 'la...  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_empty(words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if len(word) > 0:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "# Lexical Diversity\n",
    "def lexical_diversity(text):\n",
    "    if len(text) == 0:\n",
    "        diversity = 0\n",
    "    else: \n",
    "        diversity = float(len(set(text))) / len(text)\n",
    "    return diversity\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
