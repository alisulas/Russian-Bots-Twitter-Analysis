{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMOD 5410 Big Data - Weekly Assignment \\# 1\n",
    "## Detecting Russian Twitter Bots\n",
    "\n",
    "### By: Matt Emmons and Edgar Khackatryan\n",
    "\n",
    "* Find a data source, write/use a tool that gathers up some data (e.g. scrapes twitter or uses a google API)\n",
    "* Prepare somewhere between Â½ and 1 page of a description of what your data is, and a simple hypotheses on why this might have something interesting we can do with it\n",
    "\n",
    "The goal of this dataset is to explore the tweets of certain known Russian twitter 'trolls' and bots to explore the keywords, frequency of tweets and certain tendencies. These accounts often feign as being pro-right American individuals but often have highly coordinated agendas, the goal being to spread information or disinformation amongst other users on social media. The platform we are focused on will be twitter for its ease of use in scraping the relevant tweets from known deviant users. Interestingly, Twitter itself released a new set of statistics regarding their own internal investigation into Russian efforts to influence the 2016 Presidential election revealing that more than 50,000 automated accounts have links to Russian government ministries and Russia-linked organizations, specifically the IRA (Internet Research Agency).\n",
    "\n",
    "The data being used will mainly be individual from users who commonly participate in online discourse surrounding American politics, with focus on talking points and hashtags that are related to current affairs. Twitter's API provides user-controlled geolocation information and date-times of all tweets involved, included lists of users who liked, retweets and responded to questionable posts. This dataset can continually be expanded as long as Twitter's ratelimiting is not exceeded, but for now the dataset will remain small for prototyping techniques at identifying trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import config as cfg\n",
    "import pandas as pd\n",
    "from twython import Twython, TwythonError\n",
    "from IPython.display import display\n",
    "\n",
    "# authenticate with Twitter API\n",
    "twitter = Twython(cfg.APP_KEY, cfg.APP_SECRET, oauth_version=2)\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "twitter = Twython(cfg.APP_KEY, access_token = ACCESS_TOKEN)\n",
    "\n",
    "# tweets storage file\n",
    "JSON_FILE = \"data/tweets.json\"    \n",
    "\n",
    "# returns current twitter rate limit information\n",
    "def get_rate_limit():\n",
    "    '''Function that returns current Twitter API rate limit'''\n",
    "    return twitter.get_application_rate_limit_status()['resources']['search']\n",
    "\n",
    "# def load_tweets(file, skip = 0):\n",
    "#     '''Function that loads tweets from JSON file'''\n",
    "#     with open(file, 'r') as f:\n",
    "#         tweets = (json.loads(line) for i, line in enumerate(f.readlines()) if i%skip==0)\n",
    "#     return tweets\n",
    "\n",
    "def load_tweets(file):\n",
    "    '''Function that loads tweets from JSON file'''\n",
    "    with open(file, 'r') as f:\n",
    "        tweets = json.load(f)\n",
    "        return tweets\n",
    "\n",
    "def write_tweets(tweets, filename):\n",
    "    ''' Function that appends tweets to a file. '''\n",
    "    with open(filename, 'a') as f:\n",
    "        json.dump(tweets, f)\n",
    "            \n",
    "def get_tweets(user, num = 25):\n",
    "    '''\n",
    "    Function that retrives _num_ tweets from user by username\n",
    "    Returns an array of tweets\n",
    "    '''\n",
    "    tweet_array = []\n",
    "    try:\n",
    "        user_timeline = twitter.get_user_timeline(\n",
    "            screen_name = user,\n",
    "            count = num\n",
    "        )\n",
    "    except TwythonError as e:\n",
    "        print(e)\n",
    "    \n",
    "    for tweets in user_timeline:\n",
    "        tweet_array.append(tweets)\n",
    "    return tweet_array\n",
    "    \n",
    "def delete_tweets_file(filename):\n",
    "    '''\n",
    "    Function to remove tweets file\n",
    "    USE WITH CAUTION!\n",
    "    '''\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEMP: delete the tweets.json file\n",
    "# delete_tweets_file(JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known russian twitter agents\n",
    "users = [\n",
    "    'smartdissent',\n",
    "    'TEN_GOP',\n",
    "    'SparkleSoup45',\n",
    "    'MariaBartiromo',\n",
    "    'antischool_ftw',\n",
    "    'OPWolverines',\n",
    "    '55true4u',\n",
    "    'bbusa617',\n",
    "    'charlieJuliet',\n",
    "    'ChrisFromWI',\n",
    "    'SCroixFreePress',\n",
    "    'wienerherzog2',\n",
    "    'PeggyRuppe',\n",
    "    'remleona',\n",
    "    'Answers2b4u',\n",
    "]\n",
    "\n",
    "\n",
    "# get tweets and write to JSON\n",
    "tweets_memory = get_tweets(users[0], num = 3)\n",
    "\n",
    "# only create tweets.json file if it doesn't exist\n",
    "if not os.path.isfile(JSON_FILE):\n",
    "    write_tweets(tweets_memory, JSON_FILE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-22 23:25:04</td>\n",
       "      <td>#SmartDissent #MLKDay Week In Review (3/3): Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-22 23:15:10</td>\n",
       "      <td>#SmartDissent #MLKDay Week In Review (2/3): #S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-22 23:05:08</td>\n",
       "      <td>#SmartDissent #MLKDay Week In Review (1/3): Tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at                                               text\n",
       "0 2018-01-22 23:25:04  #SmartDissent #MLKDay Week In Review (3/3): Tr...\n",
       "1 2018-01-22 23:15:10  #SmartDissent #MLKDay Week In Review (2/3): #S...\n",
       "2 2018-01-22 23:05:08  #SmartDissent #MLKDay Week In Review (1/3): Tr..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: functionize this stuff\n",
    "\n",
    "# data fields we wish to extract into a dataframe from JSON\n",
    "# see data/example.json for output example\n",
    "fields  = {\n",
    "    'created_at': [],\n",
    "    'text':       [],\n",
    "}\n",
    "\n",
    "tweets_file = load_tweets(JSON_FILE)\n",
    "\n",
    "for tweet in tweets_file:\n",
    "    fields['created_at'].append(tweet['created_at'])\n",
    "    fields['text'].append(tweet['text'])\n",
    "    \n",
    "df = pd.DataFrame(fields)\n",
    "\n",
    "# Convert created_at to datetimes\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
