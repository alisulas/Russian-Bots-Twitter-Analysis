{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(101)\n",
    "rand_seed = 101\n",
    "\n",
    "n_rows = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 s, sys: 10.1 s, total: 43.6 s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ROOT = \"./csv\"\n",
    "df = pd.read_csv(\n",
    "    ROOT + \"/mergedtweets.csv\", \n",
    "    encoding='utf-8', \n",
    "    low_memory=False, \n",
    "    parse_dates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2203451, 19)\n",
      "user_id                    int64\n",
      "user_key                  object\n",
      "created_at                 int64\n",
      "created_str               object\n",
      "retweet_count              int64\n",
      "retweeted                   bool\n",
      "favorite_count             int64\n",
      "text                      object\n",
      "tweet_id                   int64\n",
      "source                    object\n",
      "hashtags                  object\n",
      "expanded_urls             object\n",
      "mentions                  object\n",
      "retweeted_status_id        int64\n",
      "in_reply_to_status_id      int64\n",
      "class                    float64\n",
      "tokenized_text            object\n",
      "stem_text                 object\n",
      "lemma_text                object\n",
      "dtype: object\n",
      "      user_id         user_key     created_at          created_str  \\\n",
      "0  2532611755        kathiemrr  1488207240000  2017-02-27 14:54:00   \n",
      "1  2531159968   traceyhappymom  1471272620000  2016-08-15 14:50:20   \n",
      "2           0    evewebster373  1435701369000  2015-06-30 21:56:09   \n",
      "3  4840551713      blacktolive  1474013088000  2016-09-16 08:04:48   \n",
      "4  1694026190  jacquelinisbest  1474227985000  2016-09-18 19:46:25   \n",
      "\n",
      "   retweet_count  retweeted  favorite_count  \\\n",
      "0              0       True               0   \n",
      "1              0       True               0   \n",
      "2              0       True               0   \n",
      "3             18      False              17   \n",
      "4              0      False               0   \n",
      "\n",
      "                                                text            tweet_id  \\\n",
      "0    #ThingsDoneByMistake kissing auntie in the lips  836227891897651200   \n",
      "1  RT @mc_derpin: #TheOlderWeGet the more pessimi...  765198948239810560   \n",
      "2  RT @dmataconis: Ready To Feel Like A Failure? ...  616002306572746752   \n",
      "3    Amen! #blacklivesmatter https://t.co/wGffaOqgzl  776693302926147584   \n",
      "4  RT @NahBabyNah: Twitchy: Chuck Todd caught out...  777594647875059712   \n",
      "\n",
      "                                              source                 hashtags  \\\n",
      "0                                                NaN  [\"ThingsDoneByMistake\"]   \n",
      "1                                                NaN        [\"TheOlderWeGet\"]   \n",
      "2                                                NaN                       []   \n",
      "3  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...     [\"Blacklivesmatter\"]   \n",
      "4  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...        [\"WakeUpAmerica\"]   \n",
      "\n",
      "                                 expanded_urls        mentions  \\\n",
      "0                                           []              []   \n",
      "1                                           []              []   \n",
      "2                                           []              []   \n",
      "3                                           []              []   \n",
      "4  [\"http://ln.is/twitchy.com/loriz-31/3yafU\"]  [\"nahbabynah\"]   \n",
      "\n",
      "   retweeted_status_id  in_reply_to_status_id  class  \\\n",
      "0                    0                      0    1.0   \n",
      "1                    0                      0    1.0   \n",
      "2                    0                      0    1.0   \n",
      "3                    0                      0    1.0   \n",
      "4   777591478206029824                      0    1.0   \n",
      "\n",
      "                                      tokenized_text  \\\n",
      "0  ['#ThingsDoneByMistake', 'kissing', 'auntie', ...   \n",
      "1  ['RT', '@mc_derpin', ':', '#TheOlderWeGet', 't...   \n",
      "2  ['RT', '@dmataconis', ':', 'Ready', 'To', 'Fee...   \n",
      "3  ['Amen', '!', '#blacklivesmatter', 'https://t....   \n",
      "4  ['RT', '@NahBabyNah', ':', 'Twitchy', ':', 'Ch...   \n",
      "\n",
      "                                           stem_text  \\\n",
      "0     ['thingsdonebymistak', 'kiss', 'aunty', 'lip']   \n",
      "1  ['rt', 'mc_derpin', '', 'theolderweget', 'pess...   \n",
      "2  ['rt', 'dmatacon', '', 'ready', 'feel', 'lik',...   \n",
      "3                    ['am', '', 'blacklivesmat', '']   \n",
      "4  ['rt', 'nahbabynah', '', 'twitchy', '', 'chuck...   \n",
      "\n",
      "                                          lemma_text  \n",
      "0  ['thingsdonebymistake', 'kiss', 'auntie', 'lips']  \n",
      "1  ['rt', 'mc_derpin', '', 'theolderweget', 'pess...  \n",
      "2  ['rt', 'dmataconis', '', 'ready', 'feel', 'lik...  \n",
      "3               ['amen', '', 'blacklivesmatter', '']  \n",
      "4  ['rt', 'nahbabynah', '', 'twitchy', '', 'chuck...  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    if len(text) == 0:\n",
    "        diversity = 0\n",
    "    else: \n",
    "        diversity = float(len(set(text))) / len(text)\n",
    "    return diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    user_id         user_key     created_at  \\\n",
      "2203446  963619824265023488        aviviavai  1518579843952   \n",
      "2203447  963619824503894016  davidinkuwait69  1518579844009   \n",
      "2203448  963619824768376833     trumpliesbot  1518579844072   \n",
      "2203449  963619825229611008        SteveoUSA  1518579844182   \n",
      "2203450  963619825036783618       RichieRoby  1518579844136   \n",
      "\n",
      "                            created_str  retweet_count  retweeted  \\\n",
      "2203446  Wed Feb 14 03:44:03 +0000 2018              0      False   \n",
      "2203447  Wed Feb 14 03:44:04 +0000 2018              0      False   \n",
      "2203448  Wed Feb 14 03:44:04 +0000 2018              0      False   \n",
      "2203449  Wed Feb 14 03:44:04 +0000 2018              0      False   \n",
      "2203450  Wed Feb 14 03:44:04 +0000 2018              0      False   \n",
      "\n",
      "         favorite_count                                               text  \\\n",
      "2203446               0  b'RT @NicCageMatch: White People Once Kept Bla...   \n",
      "2203447               0  b'The Ex Resident Obama used Kehinde Wiley to ...   \n",
      "2203448               0  b\"Come on #MAGA, admit it. Trump and his co-co...   \n",
      "2203449               0  b'History will show that @GenFlynn was a patri...   \n",
      "2203450               0  b'Not sure how one does better than applying t...   \n",
      "\n",
      "                   tweet_id  \\\n",
      "2203446  963619824265023488   \n",
      "2203447  963619824503894016   \n",
      "2203448  963619824768376833   \n",
      "2203449  963619825229611008   \n",
      "2203450  963619825036783618   \n",
      "\n",
      "                                                    source       ...        \\\n",
      "2203446  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...       ...         \n",
      "2203447  <a href=\"http://twitter.com/download/android\" ...       ...         \n",
      "2203448  <a href=\"http://twitter.com/trumpliesbot\" rel=...       ...         \n",
      "2203449  <a href=\"http://www.twitter.com\" rel=\"nofollow...       ...         \n",
      "2203450  <a href=\"https://about.twitter.com/products/tw...       ...         \n",
      "\n",
      "                                             expanded_urls  \\\n",
      "2203446  ['https://twitter.com/thewrap/status/963161707...   \n",
      "2203447                                                 []   \n",
      "2203448                                                 []   \n",
      "2203449                                                 []   \n",
      "2203450  ['https://twitter.com/i/web/status/96361982503...   \n",
      "\n",
      "                             mentions retweeted_status_id  \\\n",
      "2203446              ['NicCageMatch']  963170112567201792   \n",
      "2203447              ['ElderLansing']  963249595949158400   \n",
      "2203448               ['OMGno2trump']  963607817839153152   \n",
      "2203449  ['johncardillo', 'GenFlynn']  963394200069951488   \n",
      "2203450                            []                   0   \n",
      "\n",
      "         in_reply_to_status_id  class  \\\n",
      "2203446                      0    NaN   \n",
      "2203447                      0    NaN   \n",
      "2203448                      0    NaN   \n",
      "2203449                      0    NaN   \n",
      "2203450                      0    NaN   \n",
      "\n",
      "                                            tokenized_text  \\\n",
      "2203446  [\"b'RT\", '@NicCageMatch', ':', 'White', 'Peopl...   \n",
      "2203447  [\"b'The\", 'Ex', 'Resident', 'Obama', 'used', '...   \n",
      "2203448  ['b', '\"', 'Come', 'on', '#MAGA', ',', 'admit'...   \n",
      "2203449  [\"b'History\", 'will', 'show', 'that', '@GenFly...   \n",
      "2203450  [\"b'Not\", 'sure', 'how', 'one', 'does', 'bette...   \n",
      "\n",
      "                                                 stem_text  \\\n",
      "2203446  ['rt', 'niccagematch', '', 'whit', 'peopl', 'k...   \n",
      "2203447  ['e', 'resid', 'obam', 'us', 'kehind', 'wiley'...   \n",
      "2203448  ['', 'com', 'mag', '', 'admit', '', 'trump', '...   \n",
      "2203449  ['hist', 'show', 'genflyn', 'patriot', 'malicy...   \n",
      "2203450  ['sur', 'on', 'bet', 'apply', 'rul', 'law', 'i...   \n",
      "\n",
      "                                                lemma_text lemma_diversity  \\\n",
      "2203446  ['rt', 'niccagematch', '', 'white', 'people', ...        0.258427   \n",
      "2203447  ['e', 'resident', 'obama', 'use', 'kehinde', '...        0.083871   \n",
      "2203448  ['', 'come', 'maga', '', 'admit', '', 'trump',...        0.099338   \n",
      "2203449  ['history', 'show', 'genflynn', 'patriot', 'ma...        0.117647   \n",
      "2203450  ['sure', 'one', 'better', 'apply', 'rule', 'la...        0.164384   \n",
      "\n",
      "         stem_diversity  \n",
      "2203446        0.270588  \n",
      "2203447        0.094891  \n",
      "2203448        0.104167  \n",
      "2203449        0.131980  \n",
      "2203450        0.183206  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df['lemma_diversity'] = df['lemma_text'].apply(lexical_diversity)\n",
    "df['stem_diversity'] = df['stem_text'].apply(lexical_diversity)\n",
    "\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id         user_key     created_at          created_str  \\\n",
      "0  2532611755        kathiemrr  1488207240000  2017-02-27 14:54:00   \n",
      "1  2531159968   traceyhappymom  1471272620000  2016-08-15 14:50:20   \n",
      "2           0    evewebster373  1435701369000  2015-06-30 21:56:09   \n",
      "3  4840551713      blacktolive  1474013088000  2016-09-16 08:04:48   \n",
      "4  1694026190  jacquelinisbest  1474227985000  2016-09-18 19:46:25   \n",
      "\n",
      "   retweet_count  retweeted  favorite_count  \\\n",
      "0              0       True               0   \n",
      "1              0       True               0   \n",
      "2              0       True               0   \n",
      "3             18      False              17   \n",
      "4              0      False               0   \n",
      "\n",
      "                                                text            tweet_id  \\\n",
      "0    #ThingsDoneByMistake kissing auntie in the lips  836227891897651200   \n",
      "1  RT @mc_derpin: #TheOlderWeGet the more pessimi...  765198948239810560   \n",
      "2  RT @dmataconis: Ready To Feel Like A Failure? ...  616002306572746752   \n",
      "3    Amen! #blacklivesmatter https://t.co/wGffaOqgzl  776693302926147584   \n",
      "4  RT @NahBabyNah: Twitchy: Chuck Todd caught out...  777594647875059712   \n",
      "\n",
      "                                              source                 hashtags  \\\n",
      "0                                                NaN  [\"ThingsDoneByMistake\"]   \n",
      "1                                                NaN        [\"TheOlderWeGet\"]   \n",
      "2                                                NaN                       []   \n",
      "3  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...     [\"Blacklivesmatter\"]   \n",
      "4  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...        [\"WakeUpAmerica\"]   \n",
      "\n",
      "                                 expanded_urls        mentions  \\\n",
      "0                                           []              []   \n",
      "1                                           []              []   \n",
      "2                                           []              []   \n",
      "3                                           []              []   \n",
      "4  [\"http://ln.is/twitchy.com/loriz-31/3yafU\"]  [\"nahbabynah\"]   \n",
      "\n",
      "   retweeted_status_id  in_reply_to_status_id  class  \\\n",
      "0                    0                      0    1.0   \n",
      "1                    0                      0    1.0   \n",
      "2                    0                      0    1.0   \n",
      "3                    0                      0    1.0   \n",
      "4   777591478206029824                      0    1.0   \n",
      "\n",
      "                                      tokenized_text  \\\n",
      "0  ['#ThingsDoneByMistake', 'kissing', 'auntie', ...   \n",
      "1  ['RT', '@mc_derpin', ':', '#TheOlderWeGet', 't...   \n",
      "2  ['RT', '@dmataconis', ':', 'Ready', 'To', 'Fee...   \n",
      "3  ['Amen', '!', '#blacklivesmatter', 'https://t....   \n",
      "4  ['RT', '@NahBabyNah', ':', 'Twitchy', ':', 'Ch...   \n",
      "\n",
      "                                           stem_text  \\\n",
      "0     ['thingsdonebymistak', 'kiss', 'aunty', 'lip']   \n",
      "1  ['rt', 'mc_derpin', '', 'theolderweget', 'pess...   \n",
      "2  ['rt', 'dmatacon', '', 'ready', 'feel', 'lik',...   \n",
      "3                    ['am', '', 'blacklivesmat', '']   \n",
      "4  ['rt', 'nahbabynah', '', 'twitchy', '', 'chuck...   \n",
      "\n",
      "                                          lemma_text  diversity  \n",
      "0  ['thingsdonebymistake', 'kiss', 'auntie', 'lips']   0.448980  \n",
      "1  ['rt', 'mc_derpin', '', 'theolderweget', 'pess...   0.355932  \n",
      "2  ['rt', 'dmataconis', '', 'ready', 'feel', 'lik...   0.205357  \n",
      "3               ['amen', '', 'blacklivesmatter', '']   0.500000  \n",
      "4  ['rt', 'nahbabynah', '', 'twitchy', '', 'chuck...   0.153333  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matt/dev/ML/big-data-twitter/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# from ast import literal_eval\n",
    "\n",
    "# df_test = df.head()\n",
    "# df_test['lemma_text'] = df_test['lemma_text'].apply(literal_eval)\n",
    "# df_test['diversity'] = df_test['lemma_text'].apply(lexical_diversity)\n",
    "\n",
    "# print(df_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id         user_key     created_at          created_str  \\\n",
      "0  2532611755        kathiemrr  1488207240000  2017-02-27 14:54:00   \n",
      "1  2531159968   traceyhappymom  1471272620000  2016-08-15 14:50:20   \n",
      "2           0    evewebster373  1435701369000  2015-06-30 21:56:09   \n",
      "3  4840551713      blacktolive  1474013088000  2016-09-16 08:04:48   \n",
      "4  1694026190  jacquelinisbest  1474227985000  2016-09-18 19:46:25   \n",
      "\n",
      "   retweet_count  retweeted  favorite_count  \\\n",
      "0              0       True               0   \n",
      "1              0       True               0   \n",
      "2              0       True               0   \n",
      "3             18      False              17   \n",
      "4              0      False               0   \n",
      "\n",
      "                                                text            tweet_id  \\\n",
      "0    #ThingsDoneByMistake kissing auntie in the lips  836227891897651200   \n",
      "1  RT @mc_derpin: #TheOlderWeGet the more pessimi...  765198948239810560   \n",
      "2  RT @dmataconis: Ready To Feel Like A Failure? ...  616002306572746752   \n",
      "3    Amen! #blacklivesmatter https://t.co/wGffaOqgzl  776693302926147584   \n",
      "4  RT @NahBabyNah: Twitchy: Chuck Todd caught out...  777594647875059712   \n",
      "\n",
      "                                              source                 hashtags  \\\n",
      "0                                                NaN  [\"ThingsDoneByMistake\"]   \n",
      "1                                                NaN        [\"TheOlderWeGet\"]   \n",
      "2                                                NaN                       []   \n",
      "3  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...     [\"Blacklivesmatter\"]   \n",
      "4  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...        [\"WakeUpAmerica\"]   \n",
      "\n",
      "                                 expanded_urls        mentions  \\\n",
      "0                                           []              []   \n",
      "1                                           []              []   \n",
      "2                                           []              []   \n",
      "3                                           []              []   \n",
      "4  [\"http://ln.is/twitchy.com/loriz-31/3yafU\"]  [\"nahbabynah\"]   \n",
      "\n",
      "   retweeted_status_id  in_reply_to_status_id  class  \\\n",
      "0                    0                      0    1.0   \n",
      "1                    0                      0    1.0   \n",
      "2                    0                      0    1.0   \n",
      "3                    0                      0    1.0   \n",
      "4   777591478206029824                      0    1.0   \n",
      "\n",
      "                                      tokenized_text  \\\n",
      "0  ['#ThingsDoneByMistake', 'kissing', 'auntie', ...   \n",
      "1  ['RT', '@mc_derpin', ':', '#TheOlderWeGet', 't...   \n",
      "2  ['RT', '@dmataconis', ':', 'Ready', 'To', 'Fee...   \n",
      "3  ['Amen', '!', '#blacklivesmatter', 'https://t....   \n",
      "4  ['RT', '@NahBabyNah', ':', 'Twitchy', ':', 'Ch...   \n",
      "\n",
      "                                           stem_text  \\\n",
      "0     ['thingsdonebymistak', 'kiss', 'aunty', 'lip']   \n",
      "1  ['rt', 'mc_derpin', '', 'theolderweget', 'pess...   \n",
      "2  ['rt', 'dmatacon', '', 'ready', 'feel', 'lik',...   \n",
      "3                    ['am', '', 'blacklivesmat', '']   \n",
      "4  ['rt', 'nahbabynah', '', 'twitchy', '', 'chuck...   \n",
      "\n",
      "                                          lemma_text  \\\n",
      "0          [thingsdonebymistake, kiss, auntie, lips]   \n",
      "1    [rt, mc_derpin, , theolderweget, pessimistic, ]   \n",
      "2  [rt, dmataconis, , ready, feel, like, failure,...   \n",
      "3                       [amen, , blacklivesmatter, ]   \n",
      "4  [rt, nahbabynah, , twitchy, , chuck, todd, cat...   \n",
      "\n",
      "                                        lemma_text_2  \n",
      "0          [thingsdonebymistake, kiss, auntie, lips]  \n",
      "1        [rt, mc_derpin, theolderweget, pessimistic]  \n",
      "2  [rt, dmataconis, ready, feel, like, failure, j...  \n",
      "3                           [amen, blacklivesmatter]  \n",
      "4  [rt, nahbabynah, twitchy, chuck, todd, catch, ...  \n",
      "      user_id         user_key     created_at          created_str  \\\n",
      "0  2532611755        kathiemrr  1488207240000  2017-02-27 14:54:00   \n",
      "1  2531159968   traceyhappymom  1471272620000  2016-08-15 14:50:20   \n",
      "2           0    evewebster373  1435701369000  2015-06-30 21:56:09   \n",
      "3  4840551713      blacktolive  1474013088000  2016-09-16 08:04:48   \n",
      "4  1694026190  jacquelinisbest  1474227985000  2016-09-18 19:46:25   \n",
      "\n",
      "   retweet_count  retweeted  favorite_count  \\\n",
      "0              0       True               0   \n",
      "1              0       True               0   \n",
      "2              0       True               0   \n",
      "3             18      False              17   \n",
      "4              0      False               0   \n",
      "\n",
      "                                                text            tweet_id  \\\n",
      "0    #ThingsDoneByMistake kissing auntie in the lips  836227891897651200   \n",
      "1  RT @mc_derpin: #TheOlderWeGet the more pessimi...  765198948239810560   \n",
      "2  RT @dmataconis: Ready To Feel Like A Failure? ...  616002306572746752   \n",
      "3    Amen! #blacklivesmatter https://t.co/wGffaOqgzl  776693302926147584   \n",
      "4  RT @NahBabyNah: Twitchy: Chuck Todd caught out...  777594647875059712   \n",
      "\n",
      "                                              source                 hashtags  \\\n",
      "0                                                NaN  [\"ThingsDoneByMistake\"]   \n",
      "1                                                NaN        [\"TheOlderWeGet\"]   \n",
      "2                                                NaN                       []   \n",
      "3  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...     [\"Blacklivesmatter\"]   \n",
      "4  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...        [\"WakeUpAmerica\"]   \n",
      "\n",
      "                                 expanded_urls        mentions  \\\n",
      "0                                           []              []   \n",
      "1                                           []              []   \n",
      "2                                           []              []   \n",
      "3                                           []              []   \n",
      "4  [\"http://ln.is/twitchy.com/loriz-31/3yafU\"]  [\"nahbabynah\"]   \n",
      "\n",
      "   retweeted_status_id  in_reply_to_status_id  class  \\\n",
      "0                    0                      0    1.0   \n",
      "1                    0                      0    1.0   \n",
      "2                    0                      0    1.0   \n",
      "3                    0                      0    1.0   \n",
      "4   777591478206029824                      0    1.0   \n",
      "\n",
      "                                      tokenized_text  \\\n",
      "0  ['#ThingsDoneByMistake', 'kissing', 'auntie', ...   \n",
      "1  ['RT', '@mc_derpin', ':', '#TheOlderWeGet', 't...   \n",
      "2  ['RT', '@dmataconis', ':', 'Ready', 'To', 'Fee...   \n",
      "3  ['Amen', '!', '#blacklivesmatter', 'https://t....   \n",
      "4  ['RT', '@NahBabyNah', ':', 'Twitchy', ':', 'Ch...   \n",
      "\n",
      "                                           stem_text  \\\n",
      "0     ['thingsdonebymistak', 'kiss', 'aunty', 'lip']   \n",
      "1  ['rt', 'mc_derpin', '', 'theolderweget', 'pess...   \n",
      "2  ['rt', 'dmatacon', '', 'ready', 'feel', 'lik',...   \n",
      "3                    ['am', '', 'blacklivesmat', '']   \n",
      "4  ['rt', 'nahbabynah', '', 'twitchy', '', 'chuck...   \n",
      "\n",
      "                                          lemma_text  \\\n",
      "0          [thingsdonebymistake, kiss, auntie, lips]   \n",
      "1    [rt, mc_derpin, , theolderweget, pessimistic, ]   \n",
      "2  [rt, dmataconis, , ready, feel, like, failure,...   \n",
      "3                       [amen, , blacklivesmatter, ]   \n",
      "4  [rt, nahbabynah, , twitchy, , chuck, todd, cat...   \n",
      "\n",
      "                                        lemma_text_2  \n",
      "0          [thingsdonebymistake, kiss, auntie, lips]  \n",
      "1        [rt, mc_derpin, theolderweget, pessimistic]  \n",
      "2  [rt, dmataconis, ready, feel, like, failure, j...  \n",
      "3                           [amen, blacklivesmatter]  \n",
      "4  [rt, nahbabynah, twitchy, chuck, todd, catch, ...  \n"
     ]
    }
   ],
   "source": [
    "print(df_test.head())\n",
    "print(df_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
